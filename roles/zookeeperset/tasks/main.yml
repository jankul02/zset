- name: print configuration values    
  debug:
    msg:  '{{ app }} has  autoscale.range.min: {{ autoscale.range.min }}  '

- name: calculate replicas  
  #TODO real calculation upon node metrics and external hints
  set_fact:
    replicas: '{{autoscale.range.min | int}}'

- name: print replicas    
  debug:
    msg:  'replicas {{ replicas }}'    
  



- name: init specs    
  set_fact:
    instancesspeclist:  []  
 
- name: print allspecs   
  debug:
    msg:  'instance {{ item }}  '    
  loop: "{{ instances }}"



# - name: collect allspecs with added preset labels    
#   set_fact:
#      instancesspeclist:  "{{ instancesspeclist + [ item | combine({'spec':(item.spec  | default({}))|combine({ 'matchLabels': ( spec.matchLabels | default([]) ) + [ { 'podnamerequired': 'zk-'+ item.id } ] }  ) }) ] }}"
#   loop: "{{ instances }}"


- name: print allspecs    
  debug:
    msg:  'instancesspec {{ item }}  '    
  loop: "{{ instancesspeclist }}"

- name: print specs
  debug:
    msg:  'spec: {{ item.spec }}'    
  loop: "{{ instances }}"




- name: Search for all preset labelled app
  community.kubernetes.k8s_info:
    kind: PodPreset
    api_version: v1alpha1
    # label_selectors:
    #   - 'app = {{app}}'
  register: podpresetsbefore

- name: print podpresetsbefore
  debug:
    msg:  '{{ podpresetsbefore }}'    

- name: define zk pod presets
  community.kubernetes.k8s:
    definition:
      apiVersion: redhatcop.redhat.io/v1alpha1
      kind: PodPreset
      metadata:
        name: 'zk-{{ item.id }}'
        namespace: '{{namespace}}'
      spec: 
        selector:
          matchLabels:
            app: '{{app}}'
            podnamerequired: 'zk-{{ item.id }}'
        env: '{{ item.spec.env | default([]) }}'
        volumes: '{{ item.spec.volumes | default([]) }}'
        volumeMounts: '{{ item.spec.volumeMounts | default([]) }}'
  loop: "{{ instances }}"
  register: presettingresults

- name: print presettingresult
  debug:
    msg:  '{{ presettingresults }}'    




- name: get the configname (uuid) of the comming deployment    
  set_fact:
    configname: "zk-config-{{ data  | default({}) | to_uuid  }}"  


- name: append a stamp to have non empty data   
  set_fact:
    data_to_set: "{{ data  | default({}) | combine({ 'metacfg': 'CONFIGNAME='+configname}) }}"

- name: create cnf
  community.kubernetes.k8s:
    definition:
      apiVersion: v1
      kind: ConfigMap
      metadata: 
        name: zk-global
        namespace: '{{ namespace }}'
        labels:
          app: '{{ app }}'
          configmap: zk-global
      data: '{{data_to_set}}'  
    state: present


- name: Service hsvc
  community.kubernetes.k8s:
    definition:
      kind: Service
      apiVersion: v1
      metadata:
        name: zk-hs
        namespace: '{{ namespace }}'
        labels:
          app: '{{ app }}'    
      spec:
        ports:
        - port: 2888
          name: tcp-server
        - port: 3888
          name: tcp-leader-el
        - port: 2181
          name: tcp-client
        clusterIP: None
        selector:
          app: '{{ app }}'   



          
- name: Service zookeepersetapp-csvc
  community.kubernetes.k8s:
    definition:
      kind: Service
      apiVersion: v1
      metadata:
        name: zk-cs
        namespace: '{{ namespace }}'
        labels:
          app: '{{ app }}'    
      spec:
        ports:
        - port: 2181
          name: tcp-client
        selector:
          app: '{{ app }}'    

- name: policy for pod disruption budget 
  community.kubernetes.k8s:
    definition:
      apiVersion: policy/v1
      kind: PodDisruptionBudget
      metadata:
        name: zk-pdb
        namespace: '{{ namespace }}'
      spec:
        selector:
          matchLabels:
            app: '{{ app }}'    
        #TODO: variable for maxUnavailable
        maxUnavailable: 1  

- name: volumemounts
  set_fact:
    volumemounts:
      - name: datadir
        mountPath: /var/lib/zookeeper
      - name: zk-global
        mountPath: /mnt/zk-global
      # - name: datalogdir
      #   mountPath: /var/lib/zookeeper/log  

      

- name: volumes
  set_fact:
    volumes:
      - name: zk-global
        configMap:
          name: zk-global       

- name:  ZookeeperSet depends on
  community.kubernetes.k8s_info:
    kind: '{{item.kind}}'
    name: '{{item.name}}'
    namespace: '{{namespace}}'
  loop: '{{ updateOnChange }}'  
  register: updateonchangeresources

- name: print updateonchangeresources
  debug:
    msg:  '{{ updateonchangeresources }}'    

- name: print resources
  debug:
    msg:  'item: {{ item }}'    
  loop: '{{ updateonchangeresources.results }}'  


- name: annotate dependent update ZookeeperSet
  set_fact:
      annotation: '{{ ( annotation | default([]) ) + item.resources }}'
  loop: '{{ updateonchangeresources.results }}'  
  when: item.resources | length > 0

- name: print dependent update ZookeeperSet
  debug:
    msg:  '{{ annotation }}'  

- name: make annotation update ZookeeperSet
  set_fact:
      rolloutAnnotation: "{{ annotation | hash('sha1') }}" 


- name: Zookeeperset deployment
  community.kubernetes.k8s:
    definition:
      apiVersion: apps/v1
      kind: StatefulSet
      metadata:
        name: zk
        namespace: '{{ namespace }}'       
        labels:
          app: '{{ app }}'
      spec:
        selector:
          matchLabels:
            app: '{{ app }}'
        serviceName: zk-hs
        replicas: 3        
        updateStrategy:
          type: RollingUpdate
        podManagementPolicy: OrderedReady
        template:
          metadata:
            labels:
              app: '{{ app }}'
            annotations: 
              configname: '{{configname}}' 
              rolloutAnnotation: '{{rolloutAnnotation}}'                
          spec:
            affinity:
              podAntiAffinity:
                requiredDuringSchedulingIgnoredDuringExecution:
                  - labelSelector:
                      matchExpressions:
                        - key: "app"
                          operator: In
                          values:
                          - '{{ app }}'    
                    topologyKey: "kubernetes.io/hostname"
            containers:
            - name: kubernetes-zookeeper
              imagePullPolicy: Always
              image: '{{ image }}'
              resources:
                requests:
                  memory: "1Gi"
                  cpu: "0.5"
              ports:
              - containerPort: 2181
                name: tcp-client
              - containerPort: 2888
                name: tcp-server
              - containerPort: 3888
                name: tcp-leader-el
              command:
              - sh
              - -c
              - "/etc/confluent/docker/start-zookeeper \
                 --servers={{replicas}}"
              readinessProbe:
                exec:
                  command:
                  - sh
                  - -c
                  - "/etc/confluent/docker/zookeeper-ready 2181"
                initialDelaySeconds: 10
                timeoutSeconds: 5
              livenessProbe:
                exec:
                  command:
                  - sh
                  - -c
                  - "/etc/confluent/docker/zookeeper-ready 2181"
                initialDelaySeconds: 10
                timeoutSeconds: 5
              volumeMounts: "{{volumemounts}}"
            volumes: "{{ volumes }}"
            securityContext:
      #        runAsUser: 1000
              fsGroup: 1000            
        volumeClaimTemplates:
        - metadata:
            name: datadir
          spec:
            accessModes: [ "ReadWriteOnce" ]
            resources:
              requests:
                storage: "5Gi"
        # - metadata:
        #     name: datalogdir
        #   spec:
        #     accessModes: [ "ReadWriteOnce" ]
        #     resources:
        #       requests:
        #         storage: "5Gi"
  register: stsresult


- name: print stsresult
  debug:
    msg:  '{{ stsresult }}'    

# - name: Wait till the zk-0 is created
#   community.kubernetes.k8s_info:
#     kind: Pod
#     wait: yes
#     name: zk-0
#     namespace: '{{namespace}}'
#     wait_sleep: 10
#     wait_timeout: 360

# - name: Wait till the zk-1 is created
#   community.kubernetes.k8s_info:
#     kind: Pod
#     wait: yes
#     name: zk-1
#     namespace: '{{namespace}}'
#     wait_sleep: 10
#     wait_timeout: 360

# - name: Wait till the zk-2 is created
#   community.kubernetes.k8s_info:
#     kind: Pod
#     wait: yes
#     name: zk-2
#     namespace: '{{namespace}}'
#     wait_sleep: 10
#     wait_timeout: 360

- name: Kafka headless service
  community.kubernetes.k8s:
    definition:
      apiVersion: v1
      kind: Service
      metadata:
        name: kafka-hs
        namespace: '{{namespace}}'
        labels:
          app: '{{kafka.app}}'
      spec:
        ports:
          - port: 9092
            name: broker
        clusterIP: None
        selector:
          app: '{{kafka.app}}'

- name: Kafka service
  community.kubernetes.k8s:
    definition:
      apiVersion: v1
      kind: Service
      metadata:
        name: kafka
        namespace: '{{namespace}}'
        labels:
          app: '{{kafka.app}}'
      spec:
        ports:
          - port: 9092
            name: broker
        selector:
          app: '{{kafka.app}}'

- name: Kafka deployment
  community.kubernetes.k8s:
    definition:
      apiVersion: apps/v1
      kind: StatefulSet
      metadata:
        name: kafka
        namespace: '{{namespace}}'
        labels:
          app: '{{kafka.app}}'
      spec:
        selector:
          matchLabels:
            app: '{{kafka.app}}'
        serviceName: kafka-hs
        podManagementPolicy: OrderedReady
        replicas: 3
        updateStrategy:
          type: RollingUpdate
        template:
          metadata:
            labels:
              app: '{{kafka.app}}'
            annotations:
          spec:
            affinity:
              podAntiAffinity:
                preferredDuringSchedulingIgnoredDuringExecution:
                - weight: 1
                  podAffinityTerm:
                    labelSelector:
                      matchExpressions:
                        - key: "app"
                          operator: In
                          values:
                          - '{{kafka.app}}'
                    topologyKey: "kubernetes.io/hostname"
            containers:
            - name: kafka-broker
              image: '{{kafka.image}}'
              imagePullPolicy: "Always"
              securityContext:
                runAsUser: 0
              ports:
              - containerPort: 9092
                name: kafka
              resources:
                {}
              env:
              - name: POD_IP
                valueFrom:
                  fieldRef:
                    fieldPath: status.podIP
              - name: HOST_IP
                valueFrom:
                  fieldRef:
                    fieldPath: status.hostIP
              - name: POD_NAME
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.name
              - name: POD_NAMESPACE
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
              - name: KAFKA_HEAP_OPTS
                value: -Xms512M -Xmx512M
              - name: KAFKA_ZOOKEEPER_CONNECT
                value: "zk-hs:2181"
              - name: KAFKA_LOG_DIRS
                value: "/opt/kafka/data-0/logs"
              - name: KAFKA_LOG4J_ROOT_LOGLEVEL
                value: "DEBUG"
              - name: KAFKA_TOOLS_LOG4J_LOGLEVEL
                value: "DEBUG"
              - name: "KAFKA_LISTENER_SECURITY_PROTOCOL_MAP"
                value: "PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT"
              - name: "KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR"
                value: "3"
              # This is required because the Downward API does not yet support identification of
              # pod numbering in statefulsets. Thus, we are required to specify a command which
              # allows us to extract the pod ID for usage as the Kafka Broker ID.
              # See: https://github.com/kubernetes/kubernetes/issues/31218
              command:
              - sh
              - -exc
              - |
                echo "HOSTNAME: ${HOSTNAME} ${HOSTNAME##*-} "  && \
                export KAFKA_LOG4J_ROOT_LOGLEVEL=DEBUG && \
                export KAFKA_TOOLS_LOG4J_LOGLEVEL=DEBUG && \
                export KAFKA_BROKER_ID=${HOSTNAME##*-} && \
                export KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://${POD_NAME}.kafka-hs.${POD_NAMESPACE}:9092,EXTERNAL://${HOST_IP}:$((31090 + ${KAFKA_BROKER_ID})) && \
                unset KAFKA_PORT && \
                exec /etc/confluent/docker/run
